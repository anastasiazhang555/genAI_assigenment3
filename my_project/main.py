from fastapi import FastAPI, UploadFile, File
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
import io
from torchvision import transforms

# === helper_lib ===
from helper_lib.data_loader import get_data_loader
from helper_lib.model import get_model
from helper_lib.trainer import train_model, train_gan
from helper_lib.generator import generate_samples

# ------------------------------
# FastAPI Initialization
# ------------------------------
app = FastAPI(title="CNN + GAN API", version="2.0")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ------------------------------
# CNN model part
# ------------------------------
print("üîπ Initializing CNN Model...")
cnn_model = get_model("CNN").to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)

try:
    cnn_model.load_state_dict(torch.load("cnn_model.pth", map_location=device))
    print("‚úÖ Loaded existing CNN model weights.")
except:
    print("Training new CNN model...")
    train_loader = get_data_loader("./data", batch_size=64, train=True)
    cnn_model = train_model(cnn_model, train_loader, criterion, optimizer, device=device, epochs=5)
    torch.save(cnn_model.state_dict(), "cnn_model.pth")
    print("‚úÖ CNN Model saved to cnn_model.pth")


# ------------------------------
# GAN model part
# ------------------------------
print("üîπ Initializing GAN Model...")
gan_models = get_model("GAN")   # {'generator': G, 'discriminator': D}
G, D = gan_models["generator"].to(device), gan_models["discriminator"].to(device)


# ------------------------------
# 1: First page
# ------------------------------
@app.get("/")
def home():
    return {"message": "‚úÖ CNN + GAN API is running!"}


# ------------------------------
# 2: CNN 
# ------------------------------
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    image_bytes = await file.read()
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

    transform = transforms.Compose([
        transforms.Resize((64, 64)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    img_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = cnn_model(img_tensor)
        _, predicted = torch.max(outputs, 1)
        label = predicted.item()

    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    return {"predicted_class": label, "label": class_names[label]}


# ------------------------------
# 3: GAN training
# ------------------------------
from torchvision import datasets, transforms

@app.get("/train_gan")
def train_gan_endpoint(epochs: int = 3):
    print("üöÄ Training GAN model...")

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))  # ÂçïÈÄöÈÅìMNISTÊ†áÂáÜÂåñ
    ])
    mnist_data = datasets.MNIST(root="./data", train=True, download=True, transform=transform)
    train_loader = torch.utils.data.DataLoader(mnist_data, batch_size=64, shuffle=True)

    trained_G, trained_D = train_gan(gan_models, train_loader, device=device, epochs=epochs)
    torch.save(trained_G.state_dict(), "gan_generator.pth")
    torch.save(trained_D.state_dict(), "gan_discriminator.pth")
    return {"message": f"‚úÖ GAN trained for {epochs} epochs and saved to disk."}


# ------------------------------
# 4: GAN generating
# ------------------------------
from fastapi.responses import FileResponse

@app.get("/generate_gan")
def generate_gan_endpoint(num_samples: int = 5):
    print(f"üñºÔ∏è Generating {num_samples} GAN images...")
    try:
        G.load_state_dict(torch.load("gan_generator.pth", map_location=device))
        print("‚úÖ Loaded trained GAN generator weights.")
    except:
        print("‚ö†Ô∏è No pretrained GAN found. Using untrained generator.")
    output_path = generate_samples(G, device=device, num_samples=num_samples)
    return {"message": f"‚úÖ Generated {num_samples} images", "file_path": output_path}
